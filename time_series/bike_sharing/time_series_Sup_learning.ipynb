{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "# might be add in requirements.txt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "# Statsmodel\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "# Scikit-learn\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df_train = pd.read_csv(\"./train.csv\", parse_dates=[\"datetime\"])\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime from object to datetime type\n",
    "df_train['datetime'] = pd.to_datetime(df_train['datetime'])\n",
    "# Set datetime as index\n",
    "df_train = df_train.set_index(df_train.datetime)\n",
    "# Drop datetime column snce it becomes our index\n",
    "df_train.drop('datetime', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hour, day and month variables from datetime index --> New Features, is it worth it to add the year also? \n",
    "df_train['hour'] = df_train.index.hour\n",
    "df_train['day'] = df_train.index.day\n",
    "df_train['month'] = df_train.index.month\n",
    "# Drop casual and registered columns, since we are predicting the count (sum of the casual and registered columns)\n",
    "df_train.drop(['casual', 'registered'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check our engineerd dataset\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to use last week data as validation\n",
    "horizon = 24*7 # --> data is reported by hour\n",
    "\n",
    "# Count is our variable of interest, is what we are going to predict. \n",
    "# We use all the remaining columns as features\n",
    "X = df_train.drop('count', axis=1)\n",
    "y = df_train['count']\n",
    "\n",
    "# Take last week of the dataset for validation\n",
    "X_train, X_val = X.iloc[:-horizon,:], X.iloc[-horizon:,:]\n",
    "y_train, y_val = y.iloc[:-horizon], y.iloc[-horizon:]\n",
    "\n",
    "# Build your model and train it (fit)\n",
    "reg = GradientBoostingRegressor(random_state=0)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to predict \n",
    "predictions = reg.predict(X_val)\n",
    "# Fix the predictions, we know that we cannot have -1 rented bike\n",
    "predictions[predictions < 0] =0\n",
    "\n",
    "# Calculate error  \n",
    "mae = np.round(mean_absolute_error(y_val, predictions), 3)\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_val, predictions)}%\")\n",
    "print(f\"MAE: {np.round(mean_absolute_error(y_val, predictions), 3)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction for the last week of the dataset\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "plt.title(f'Real vs Prediction - MAE {mae}', fontsize=20)\n",
    "plt.plot(y_val, label='Actual values')\n",
    "plt.plot(pd.Series(predictions, index=y_val.index), 'g', label='Predicted values')\n",
    "plt.xlabel('Hour', fontsize=16)\n",
    "plt.ylabel('Number of Shared Bikes', fontsize=16)\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#create a dataframe with the variable importances of the model\n",
    "df_importances = pd.DataFrame({\n",
    "    'feature': reg.feature_names_in_,\n",
    "    'importance': reg.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "#plot variable importances of the model\n",
    "plt.title('Variable Importances', fontsize=16)\n",
    "sns.barplot(x=df_importances.importance, y=df_importances.feature, orient='h')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes, if we add lags (difference between data points during a period of time) the model's performance might improve. \n",
    "# So, let's create 1 week lag variable by shifting the target value for 1 week\n",
    "df_train['count_prev_week_same_hour'] = df_train['count'].shift(24*7)\n",
    "\n",
    "# Drop NaNs after feature engineering\n",
    "df_train.dropna(how='any', axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train again\n",
    "\n",
    "# We are going to use last week data as validation\n",
    "horizon = 24*7 # --> data is reported by hour\n",
    "\n",
    "# Count is our variable of interest, is what we are going to predict. \n",
    "# We use all the remaining columns as features\n",
    "X = df_train.drop('count', axis=1)\n",
    "y = df_train['count']\n",
    "\n",
    "# Take last week of the dataset for validation\n",
    "X_train, X_val = X.iloc[:-horizon,:], X.iloc[-horizon:,:]\n",
    "y_train, y_val = y.iloc[:-horizon], y.iloc[-horizon:]\n",
    "\n",
    "# Build your model and train it (fit)\n",
    "reg = GradientBoostingRegressor(random_state=0)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to predict \n",
    "predictions = reg.predict(X_val)\n",
    "# Fix the predictions, we know that we cannot have -1 rented bike\n",
    "predictions[predictions < 0] =0\n",
    "\n",
    "# Calculate error  \n",
    "mae = np.round(mean_absolute_error(y_val, predictions), 3)\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_val, predictions)}%\")\n",
    "print(f\"MAE: {np.round(mean_absolute_error(y_val, predictions), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction for the last week of the dataset\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "plt.title(f'Real vs Prediction - MAE {mae}', fontsize=20)\n",
    "plt.plot(y_val, label='Actual values')\n",
    "plt.plot(pd.Series(predictions, index=y_val.index), 'g', label='Predicted values')\n",
    "plt.xlabel('Hour', fontsize=16)\n",
    "plt.ylabel('Number of Shared Bikes', fontsize=16)\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#create a dataframe with the variable importances of the model\n",
    "df_importances = pd.DataFrame({\n",
    "    'feature': reg.feature_names_in_,\n",
    "    'importance': reg.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "#plot variable importances of the model\n",
    "plt.title('Variable Importances', fontsize=16)\n",
    "sns.barplot(x=df_importances.importance, y=df_importances.feature, orient='h')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing in the real test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create the predictions on the real test set. \n",
    "# We can use the data from the last month as training set and then, use the model to predict the following ten days.\n",
    "\n",
    "# Import the data, again\n",
    "df_train = pd.read_csv(\"./train.csv\", parse_dates=[\"datetime\"])\n",
    "df_test = pd.read_csv(\"./test.csv\", parse_dates=[\"datetime\"])\n",
    "\n",
    "# Convert datetime from object to datetime type\n",
    "df_train['datetime'] = pd.to_datetime(df_train['datetime'])\n",
    "df_test['datetime'] = pd.to_datetime(df_test['datetime'])\n",
    "# Set datetime as index\n",
    "df_train = df_train.set_index(df_train.datetime)\n",
    "df_test = df_test.set_index(df_test.datetime)\n",
    "# Drop datetime column snce it becomes our index\n",
    "df_train.drop('datetime', axis=1, inplace=True)\n",
    "df_test.drop('datetime', axis=1, inplace=True)\n",
    "# Create hour, day and month variables from datetime index --> New Features, is it worth it to add the year also? \n",
    "df_train['hour'] = df_train.index.hour\n",
    "df_test['hour'] = df_test.index.hour\n",
    "df_train['day'] = df_train.index.day\n",
    "df_test['day'] = df_test.index.day\n",
    "df_train['month'] = df_train.index.month\n",
    "df_test['month'] = df_test.index.month\n",
    "# Drop casual and registered columns, since we are predicting the count (sum of the casual and registered columns). \n",
    "# Test set does not have them\n",
    "df_train.drop(['casual', 'registered'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# We are going to use last month data from the training set to validate\n",
    "horizon_train = 24*20 # --> data is reported by hour for the first 20 days of the month\n",
    "\n",
    "# Count is our variable of interest, is what we are going to predict. \n",
    "# We use all the remaining columns as features\n",
    "X = df_train.drop('count', axis=1)\n",
    "y = df_train['count']\n",
    "\n",
    "# Take last month of the dataset for validation\n",
    "X_train = X.iloc[-horizon_train:,:]\n",
    "y_train = y.iloc[-horizon_train:]\n",
    "\n",
    "# We do the same for testing.\n",
    "horizon_test = 24*10 # --> data is reported by hour for the last 10 days of the month\n",
    "X_test = df_test.iloc[-horizon_test:,:]\n",
    "\n",
    "# Build your model and train it (fit)\n",
    "reg = GradientBoostingRegressor(random_state=42)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to predict \n",
    "predictions = reg.predict(X_test)\n",
    "# Fix the predictions, we know that we cannot have -1 rented bike\n",
    "predictions[predictions < 0] =0\n",
    "\n",
    "# Notice that we cannot calculate the error because there is no actual value to compare to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction for the last week of the dataset\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "plt.plot(pd.Series(predictions, index=X_test.index), 'g', label='Predicted values')\n",
    "plt.xlabel('Hour', fontsize=16)\n",
    "plt.ylabel('Number of Shared Bikes', fontsize=16)\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5895fc9c045060c0483fdecda8d9b833399f927ce766293a7dd4fef0f0b97a32"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('iot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
